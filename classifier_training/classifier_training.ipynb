{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d8baaab",
   "metadata": {},
   "source": [
    "# SVM Classifier Training\n",
    "\n",
    "This notebook trains a classifier for use in <em>The Shapeshifter</em>. The dataset should be provided in the form of a single audio file for each <em>phase</em> of performance containing all examples. The dataset should provide examples of the vocalisations associated by the performer with each <em>phase</em>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e6c04a",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7ac59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from sklearn import *\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from pyAudioAnalysis import audioBasicIO as aIO\n",
    "from pyAudioAnalysis import audioSegmentation as aS\n",
    "from maad import sound\n",
    "from maad.rois import find_rois_cwt\n",
    "from maad.util import plot_spectrogram\n",
    "import scipy\n",
    "from scipy import signal\n",
    "import sklearn\n",
    "from joblib import dump,load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6710118",
   "metadata": {},
   "source": [
    "## 2. Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5774b507",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 48000\n",
    "\n",
    "# filepath where all audio files are located\n",
    "\n",
    "filepath = ''\n",
    "\n",
    "# audio filename - This notebook assumes the audio files are named in the manner \"filename\"_\"phase\".wav\n",
    "\n",
    "filename = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bd2fa2",
   "metadata": {},
   "source": [
    "## 3. Import Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceadab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dict = {}\n",
    "\n",
    "for i in range(1, 10):\n",
    "    ds_dict[\"phase_\" + str(i)], _ = librosa.load(filepath + '/' + filename + str(i) + \".wav\", sr=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af672822",
   "metadata": {},
   "source": [
    "## 4. Normalise Audio Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ca1f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ds_dict)):\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    if np.abs(ds_dict['phase_' + str(i)].max()) >= np.abs(ds_dict['phase_' + str(i)].min()):\n",
    "        ds_dict['phase_' + str(i)] = ds_dict['phase_' + str(i)]/ds_dict['phase_' + str(i)].max()\n",
    "\n",
    "    else:\n",
    "        ds_dict['phase_' + str(i)] = ds_dict['phase_' + str(i)]/np.abs(ds_dict['phase_' + str(i)].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329fd23c",
   "metadata": {},
   "source": [
    "## 5. Define Functions to Extract Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbb2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtains a spectrogram of an audio file\n",
    "\n",
    "def getSpectrogram(audio, sr, plot=True):\n",
    "    \n",
    "    s = audio\n",
    "    Sxx, tn, fn, ext = sound.spectrogram(s, sr, nperseg=1024, noverlap=512)\n",
    "    if plot == True:\n",
    "        plot_spectrogram(Sxx, extent=ext, db_range=60, gain=20, colorbar=False, figsize=(2.5,10))\n",
    "        \n",
    "    return Sxx, tn, fn, ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be85f67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the frequency band with the highest energy to provide as centre freq to regions of interest\n",
    "\n",
    "def getCentreFreq(spectrogram, fn):\n",
    "    \n",
    "    mean = 0\n",
    "    centre = 0\n",
    "\n",
    "    # Iterate over rows in spectrogram\n",
    "    for row in range(spectrogram.shape[0]):\n",
    "        \n",
    "        # Take mean value\n",
    "        temp = np.mean(spectrogram[row])\n",
    "        \n",
    "        # Replace if higher\n",
    "        if temp > mean:\n",
    "            \n",
    "            centre = row\n",
    "            mean = temp\n",
    "    \n",
    "    # Return frequency band\n",
    "    return fn[centre]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2f27fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segments and audio file based upon regions of interest identified in a spectrogram\n",
    "# If display == True plots are created\n",
    "\n",
    "def segmentAudio(audio, spectrogram, centre, sr, display=True):\n",
    "    \n",
    "    # Find regions of interest\n",
    "    df = find_rois_cwt(audio, sr, flims=(centre-(centre/2), centre+(centre/2)), tlen=1, th=0, display=display, figsize=(10,6))\n",
    "    if display == True:\n",
    "        print(df)\n",
    "    \n",
    "    # Declare list to append\n",
    "    audio_list = []\n",
    "\n",
    "    # Segment audio\n",
    "    for row in range(df.shape[0]):\n",
    "        aud = (audio[int(df.iloc[row][1]*sr):int(df.iloc[row][3]*sr)])\n",
    "        \n",
    "        if np.abs(aud.max()) >= np.abs(aud.min()):\n",
    "            \n",
    "            aud = aud/aud.max()\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            aud = aud/np.abs(aud.min())\n",
    "            \n",
    "        audio_list.append(aud)\n",
    "    \n",
    "    # Display if true\n",
    "    if display == True:\n",
    "                             \n",
    "        testy = []\n",
    "\n",
    "        for i in audio_list:\n",
    "            i = np.array(i)\n",
    "            testy.append(i)\n",
    "            testy.append(np.zeros(int(sr/2)))\n",
    "\n",
    "        testy = np.concatenate(testy)\n",
    "        testy = testy.flatten()\n",
    "                             \n",
    "        ipd.Audio(testy, rate=sr)\n",
    "        \n",
    "    return(audio_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63aca9d",
   "metadata": {},
   "source": [
    "## 6. Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a61689",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "for i in range(len(ds_dict)):\n",
    "    i += 1\n",
    "    Sxx, tn, fn, ext = getSpectrogram(ds_dict['phase_' + str(i)], sr)\n",
    "    centre_freq = getCentreFreq(Sxx, fn)\n",
    "    segments = segmentAudio(ds_dict['phase_' + str(i)], Sxx, centre_freq, sr)\n",
    "    dataset.append(segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de8c0fd",
   "metadata": {},
   "source": [
    "## 7. Create labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0fb68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "\n",
    "for i, x in enumerate(dataset):\n",
    "    labs = []\n",
    "    for j in range(len(x)):\n",
    "        labels.append(i)\n",
    "        \n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723a64c5",
   "metadata": {},
   "source": [
    "## 8. Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ce2d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-Dimensional linear interpolation\n",
    "\n",
    "def lin_interp_1d(data, out_size): # From Stefano Fasciani\n",
    "    \n",
    "    in_size = data.shape[0]\n",
    "    x_in = np.arange(0,in_size)\n",
    "    interpolator = scipy.interpolate.interp1d(x_in, data)\n",
    "    x_out = np.arange(0,in_size-1,((in_size-1)/out_size))\n",
    "    output = interpolator(x_out)\n",
    "    output = output[0:out_size]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f3031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract rms and spectral centroid\n",
    "\n",
    "feats = np.zeros((len(labels), 200))\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for clas in dataset:\n",
    "    for audio in clas:\n",
    "        rms = librosa.feature.rms(y=audio)\n",
    "        rms = rms.flatten()\n",
    "        rms = lin_interp_1d(rms, 100)\n",
    "        feats[counter,:][0:100] = rms\n",
    "        cent = librosa.feature.spectral_centroid(y=audio,sr=sr)\n",
    "        cent = cent.flatten()\n",
    "        cent = lin_interp_1d(mels, 100)\n",
    "        feats[counter,:][100:200] = cent\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa59bc6f",
   "metadata": {},
   "source": [
    "## 9. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af6cf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = sklearn.svm.SVC(kernel='rbf', C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987268fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.fit(feats_train, lab_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbfcbfb",
   "metadata": {},
   "source": [
    "## 10. Repeat 1000 Times and Calculate Mean F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6882cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = []\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    feats_train, feats_test, lab_train, lab_test = sklearn.model_selection.train_test_split(feats, labels, test_size=0.2)\n",
    "    svm = sklearn.svm.SVC(kernel='rbf', C=10)\n",
    "    svm.fit(feats_train, lab_train)\n",
    "    lab_predict =  svm.predict(feats_test)\n",
    "    f1.append(sklearn.metrics.f1_score(lab_test, lab_predict, average='weighted'))\n",
    "    \n",
    "f1 = np.array(f1)\n",
    "np.mean(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c852ebab",
   "metadata": {},
   "source": [
    "## 11. Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c58a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = ''\n",
    "\n",
    "dump(svm, filepath + '/' + 'classifier.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
