{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95558860-b8b4-4737-bf99-2614f6b2ea6c",
   "metadata": {},
   "source": [
    "# 2. Correlation Calculation\n",
    "\n",
    "Notebook to calculate the correlation between the two sinusoids extracted in notebook 1 and perform statistical tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a504742f",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8453e37-ed40-4272-b8ce-612d2cc7f641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skvideo\n",
    "import cv2\n",
    "from scipy.stats import multivariate_normal\n",
    "import os\n",
    "from scipy import signal, stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1714db",
   "metadata": {},
   "source": [
    "## 2. Define Functions and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e8a9de-8533-4d10-94ff-ca5909170fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class for storing two sinusoid arrays\n",
    "# One for storing laser point in top half\n",
    "# One for storing visualisation in bottom halfb\n",
    "\n",
    "class swing_rec:\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        \n",
    "        self.name = name\n",
    "        self.top_array = 0\n",
    "        self.bottom_array = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aef85f3",
   "metadata": {},
   "source": [
    "## 3. Calculate Correlations, Summary Statistics, and Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d2535c-88ae-454f-aff2-8f56aa13ae7d",
   "metadata": {},
   "source": [
    "### 3.1. One Position Marker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a241c426",
   "metadata": {},
   "source": [
    "### 3.1.1. Load Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588cd727-d3f8-41bf-8a26-fa1868a89b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath to pickle file containing swing_rec objects\n",
    "path = ''\n",
    "\n",
    "# Declare dictionary for correlations\n",
    "rb_1_dict = {}\n",
    "\n",
    "\n",
    "for file in sorted(os.listdir(path)):\n",
    "    \n",
    "    if '01.pkl' in file:\n",
    "        \n",
    "        filepath = path + '/' + file\n",
    "\n",
    "        # Open pickle file\n",
    "        with open(filepath, 'rb') as file:\n",
    "            \n",
    "            dicty = pickle.load(file)\n",
    "\n",
    "            # Place swing_rec objects in dict\n",
    "            for key, item in dicty.items():\n",
    "\n",
    "                rb_1_dict[key] = item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f36bee",
   "metadata": {},
   "source": [
    "### 3.1.2. Calculate Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f8ed75-b0cb-45ec-9d2b-3ec74b2c61dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare dictionary for correlations\n",
    "rb_1_corrs_dict = {}\n",
    "\n",
    "# Iterate through swing_rec objects\n",
    "for key, item in sorted(rb_1_dict.items()):\n",
    "    \n",
    "    # Set arrays\n",
    "    top = item.top_array\n",
    "    bottom = item.bottom_array\n",
    "    \n",
    "    # Calculate correlation\n",
    "    corr = signal.correlate(bottom, top)\n",
    "\n",
    "    # Calculate correlation lags\n",
    "    lags = signal.correlation_lags(len(bottom), len(top))\n",
    "\n",
    "    # Normalise correlation\n",
    "    corr = corr/np.max(corr)\n",
    "    \n",
    "    # Find peaks in correlation\n",
    "    cpeaks = signal.find_peaks(corr)[0]\n",
    "    \n",
    "    # Find the maximum lag - provides latency in video frames\n",
    "    latency_samps = lags[cpeaks][np.where(lags[cpeaks] > 0)[0]][0]\n",
    "    \n",
    "    # Place in dict\n",
    "    rb_1_corrs_dict[key] = latency_samps\n",
    "    \n",
    "    # Plot sinusoids with latency compensation to check\n",
    "    fig = plt.figure(figsize=(12, 6), dpi=300)\n",
    "\n",
    "    plt.plot(bottom, label='Visualisation')\n",
    "    plt.plot(np.roll(top, latency_samps), label='Laser Point')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.suptitle(key)\n",
    "    plt.title('Latency: ' + str(latency_samps) + 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1741dd",
   "metadata": {},
   "source": [
    "### 3.1.3. Place in dataframe and calculate summary statistics for latency in samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10c8c63-5cb1-4e63-8e88-ca3086e3943c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract information from keys\n",
    "keys_info = [key.split('-')[:3] for key in rb_1_corrs_dict.keys()]\n",
    "\n",
    "# Create a DataFrame\n",
    "rb1_df = pd.DataFrame(keys_info, columns=['RB', 'Cycle', 'Phase'])\n",
    "\n",
    "# Drop duplicates\n",
    "rb1_df = rb1_df.drop_duplicates()\n",
    "\n",
    "# Add columns for each last part of the key\n",
    "for key, value in rb_1_corrs_dict.items():\n",
    "    last_part = key.split('-')[-1].split('.')[0]\n",
    "    column_name = f\"Rep{last_part}\"\n",
    "    rb1_df[column_name] = rb1_df.apply(lambda row: rb_1_corrs_dict.get(f\"{row['RB']}-{row['Cycle']}-{row['Phase']}-{last_part}.mp4\"), axis=1)\n",
    "\n",
    "# Sort columns\n",
    "rb1_df = rb1_df.sort_index(axis=1)\n",
    "\n",
    "# Reset the index\n",
    "rb1_df = rb1_df.reset_index(drop=True)\n",
    "\n",
    "# Add extra columns for summary statistics\n",
    "rep_columns = [col for col in rb1_df.columns if col.startswith('Rep')]\n",
    "\n",
    "# Add summary statistic columns\n",
    "rb1_df['Min'] = rb1_df[rep_columns].min(axis=1)\n",
    "rb1_df['Mean'] = rb1_df[rep_columns].mean(axis=1)\n",
    "rb1_df['Median'] = rb1_df[rep_columns].median(axis=1)\n",
    "rb1_df['Max'] = rb1_df[rep_columns].max(axis=1)\n",
    "rb1_df['StdDev'] = rb1_df[rep_columns].std(axis=1)\n",
    "\n",
    "# Calculate standard error\n",
    "rb1_df['StdError'] = rb1_df.apply(lambda row: row['StdDev'] / np.sqrt(len(rep_columns)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32654b0-561f-45ae-b743-2b2adeb1b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataframe\n",
    "rb1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ab9a06-cbca-4a1b-9588-8789b4c526e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save csv\n",
    "rb1_df.to_csv('rb1_corr_frames.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd5269c",
   "metadata": {},
   "source": [
    "### 3.1.4. Place in dataframe and calculate summary statistics for latency in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffe390b-a28a-43fd-b32b-c1a282aa3ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract information from keys\n",
    "keys_info = [key.split('-')[:3] for key in rb_1_corrs_dict.keys()]\n",
    "\n",
    "# Create a DataFrame\n",
    "rb1_df = pd.DataFrame(keys_info, columns=['RB', 'Cycle', 'Phase'])\n",
    "\n",
    "# Drop duplicates\n",
    "rb1_df = rb1_df.drop_duplicates()\n",
    "\n",
    "# Add columns for each last part of the key\n",
    "for key, value in rb_1_corrs_dict.items():\n",
    "    last_part = key.split('-')[-1].split('.')[0]\n",
    "    column_name = f\"Rep{last_part}\"\n",
    "    rb1_df[column_name] = rb1_df.apply(lambda row: rb_1_corrs_dict.get(f\"{row['RB']}-{row['Cycle']}-{row['Phase']}-{last_part}.mp4\"), axis=1)\n",
    "\n",
    "# Sort columns\n",
    "rb1_df = rb1_df.sort_index(axis=1)\n",
    "\n",
    "# Reset the index\n",
    "rb1_df = rb1_df.reset_index(drop=True)\n",
    "\n",
    "# Multiply all values by 1/120 to get value in seconds\n",
    "rb1_df.iloc[:, 3:] = rb1_df.iloc[:, 3:].multiply(1/120)\n",
    "\n",
    "# Add extra columns for summary statistics\n",
    "rep_columns = [col for col in rb1_df.columns if col.startswith('Rep')]\n",
    "\n",
    "# Add summary statistic columns\n",
    "rb1_df['Min'] = rb1_df[rep_columns].min(axis=1)\n",
    "rb1_df['Mean'] = rb1_df[rep_columns].mean(axis=1)\n",
    "rb1_df['Median'] = rb1_df[rep_columns].median(axis=1)\n",
    "rb1_df['Max'] = rb1_df[rep_columns].max(axis=1)\n",
    "rb1_df['StdDev'] = rb1_df[rep_columns].std(axis=1)\n",
    "\n",
    "# Calculates standard error (assuming standard deviation is population std dev)\n",
    "rb1_df['StdError'] = rb1_df.apply(lambda row: row['StdDev'] / np.sqrt(len(rep_columns)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03bc129-89e9-4b35-ad2a-ecf539d16933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataframe\n",
    "rb1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea20346-617f-412e-b35f-cbfd69837da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save csv\n",
    "rb1_df.to_csv('rb1_corr_seconds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c415403",
   "metadata": {},
   "source": [
    "### 3.1.5. Create Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5aa35a-0e4f-4ca0-9553-401153fda9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the means of each phase across performance\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(rb1_df['Cycle'].astype(str) + '-P' + rb1_df['Phase'].astype(str), rb1_df['Mean'], marker='o')\n",
    "plt.xlabel('Performance Phase')\n",
    "plt.ylabel('Mean Latency (Seconds)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Mean Latency Across Performance Phases')\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4244d2-b973-4b39-b53d-8914a565009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots of cycle means regardless of phase\n",
    "\n",
    "# Calculate means for each cycle\n",
    "cycle_means = rb1_df.groupby('Cycle')['Mean'].mean()\n",
    "\n",
    "# Plot the box plot\n",
    "plt.figure(figsize=(6, 3.1))\n",
    "boxprops = dict(facecolor='white', color='black')\n",
    "plt.boxplot([rb1_df[rb1_df['Cycle'] == cycle]['Mean'] for cycle in rb1_df['Cycle'].unique()],\n",
    "            labels=rb1_df['Cycle'].unique(), showfliers=True, patch_artist=True, boxprops=boxprops)\n",
    "plt.xlabel('Cycle')\n",
    "plt.ylabel('Mean Latency (Seconds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('rb_1_cycle_means_box.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b436d765-1053-4752-97b4-c8894d93886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots of phase means regardless of cycle\n",
    "\n",
    "# Calculate means for each phase\n",
    "phase_means = rb1_df.groupby('Phase')['Mean'].mean()\n",
    "\n",
    "# Plot the box plot\n",
    "plt.figure(figsize=(6, 3.1))\n",
    "boxprops = dict(facecolor='white', color='black')  # Set box color to white\n",
    "plt.boxplot([rb1_df[rb1_df['Phase'] == phase]['Mean'] for phase in rb1_df['Phase'].unique()],\n",
    "            labels=rb1_df['Phase'].unique(), showfliers=True, patch_artist=True, boxprops=boxprops)\n",
    "plt.xlabel('Phase')\n",
    "plt.ylabel('Mean Latency (Seconds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('rb_1_phase_means_box.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4961a8af",
   "metadata": {},
   "source": [
    "### 3.1.6. Print Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95810c7c-0477-4a5a-acca-a438fafb5abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for the whole DataFrame\n",
    "whole_dataframe_summary = {\n",
    "    'Min': round(rb1_df['Mean'].min(), 3),\n",
    "    'Max': round(rb1_df['Mean'].max(), 3),\n",
    "    'Mean': round(rb1_df['Mean'].mean(), 3),\n",
    "    'Median': round(rb1_df['Mean'].median(), 3),\n",
    "    'StdDev': round(rb1_df['Mean'].std(), 3),\n",
    "    'StdError': round(rb1_df['Mean'].std() / np.sqrt(len(rb1_df)), 3),\n",
    "}\n",
    "\n",
    "print(\"Summary Statistics for the Whole DataFrame:\")\n",
    "print(whole_dataframe_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbbace8",
   "metadata": {},
   "source": [
    "### 3.2. Five Position Markers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8df0f35",
   "metadata": {},
   "source": [
    "### 3.2.1. Load Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6540ce67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath to pickle file containing swing_rec objects\n",
    "path = ''\n",
    "\n",
    "# Declare dictionary for correlations\n",
    "rb_5_dict = {}\n",
    "\n",
    "\n",
    "for file in sorted(os.listdir(path)):\n",
    "    \n",
    "    if '05.pkl' in file:\n",
    "        \n",
    "        filepath = path + '/' + file\n",
    "\n",
    "        # Open pickle file\n",
    "        with open(filepath, 'rb') as file:\n",
    "            \n",
    "            dicty = pickle.load(file)\n",
    "\n",
    "            # Place swing_rec objects in dict\n",
    "            for key, item in dicty.items():\n",
    "\n",
    "                rb_5_dict[key] = item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282e81aa",
   "metadata": {},
   "source": [
    "### 3.2.2. Calculate Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cad1aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare dictionary for correlations\n",
    "rb_5_corrs_dict = {}\n",
    "\n",
    "# Iterate through swing_rec objects\n",
    "for key, item in sorted(rb_5_dict.items()):\n",
    "    \n",
    "    # Set arrays\n",
    "    top = item.top_array\n",
    "    bottom = item.bottom_array\n",
    "    \n",
    "    # Calculate correlation\n",
    "    corr = signal.correlate(bottom, top)\n",
    "\n",
    "    # Calculate correlation lags\n",
    "    lags = signal.correlation_lags(len(bottom), len(top))\n",
    "\n",
    "    # Normalise correlation\n",
    "    corr = corr/np.max(corr)\n",
    "    \n",
    "    # Find peaks in correlation\n",
    "    cpeaks = signal.find_peaks(corr)[0]\n",
    "    \n",
    "    # Find the maximum lag - provides latency in video frames\n",
    "    latency_samps = lags[cpeaks][np.where(lags[cpeaks] > 0)[0]][0]\n",
    "    \n",
    "    # Place in dict\n",
    "    rb_5_corrs_dict[key] = latency_samps\n",
    "    \n",
    "    # Plot sinusoids with latency compensation to check\n",
    "    fig = plt.figure(figsize=(12, 6), dpi=300)\n",
    "\n",
    "    plt.plot(bottom, label='Visualisation')\n",
    "    plt.plot(np.roll(top, latency_samps), label='Laser Point')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.suptitle(key)\n",
    "    plt.title('Latency: ' + str(latency_samps) + 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2e4aa9",
   "metadata": {},
   "source": [
    "### 3.2.3. Place in dataframe and calculate summary statistics for latency in samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b0708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract information from keys\n",
    "keys_info = [key.split('-')[:3] for key in rb_5_corrs_dict.keys()]\n",
    "\n",
    "# Create a DataFrame\n",
    "rb5_df = pd.DataFrame(keys_info, columns=['RB', 'Cycle', 'Phase'])\n",
    "\n",
    "# Drop duplicates\n",
    "rb5_df = rb5_df.drop_duplicates()\n",
    "\n",
    "# Add columns for each last part of the key\n",
    "for key, value in rb_5_corrs_dict.items():\n",
    "    last_part = key.split('-')[-1].split('.')[0]\n",
    "    column_name = f\"Rep{last_part}\"\n",
    "    rb5_df[column_name] = rb5_df.apply(lambda row: rb_5_corrs_dict.get(f\"{row['RB']}-{row['Cycle']}-{row['Phase']}-{last_part}.mp4\"), axis=1)\n",
    "\n",
    "# Sort columns\n",
    "rb5_df = rb5_df.sort_index(axis=1)\n",
    "\n",
    "# Reset the index\n",
    "rb5_df = rb5_df.reset_index(drop=True)\n",
    "\n",
    "# Add extra columns for summary statistics\n",
    "rep_columns = [col for col in rb5_df.columns if col.startswith('Rep')]\n",
    "\n",
    "# Add summary statistic columns\n",
    "rb5_df['Min'] = rb5_df[rep_columns].min(axis=1)\n",
    "rb5_df['Mean'] = rb5_df[rep_columns].mean(axis=1)\n",
    "rb5_df['Median'] = rb5_df[rep_columns].median(axis=1)\n",
    "rb5_df['Max'] = rb5_df[rep_columns].max(axis=1)\n",
    "rb5_df['StdDev'] = rb5_df[rep_columns].std(axis=1)\n",
    "\n",
    "# Calculate standard error\n",
    "rb5_df['StdError'] = rb5_df.apply(lambda row: row['StdDev'] / np.sqrt(len(rep_columns)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc7a74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataframe\n",
    "rb5_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87622274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save csv\n",
    "rb5_df.to_csv('rb5_corr_frames.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1101c595",
   "metadata": {},
   "source": [
    "### 3.2.4. Place in dataframe and calculate summary statistics for latency in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deb3234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract information from keys\n",
    "keys_info = [key.split('-')[:3] for key in rb_5_corrs_dict.keys()]\n",
    "\n",
    "# Create a DataFrame\n",
    "rb5_df = pd.DataFrame(keys_info, columns=['RB', 'Cycle', 'Phase'])\n",
    "\n",
    "# Drop duplicates\n",
    "rb5_df = rb5_df.drop_duplicates()\n",
    "\n",
    "# Add columns for each last part of the key\n",
    "for key, value in rb_5_corrs_dict.items():\n",
    "    last_part = key.split('-')[-1].split('.')[0]\n",
    "    column_name = f\"Rep{last_part}\"\n",
    "    rb5_df[column_name] = rb5_df.apply(lambda row: rb_5_corrs_dict.get(f\"{row['RB']}-{row['Cycle']}-{row['Phase']}-{last_part}.mp4\"), axis=1)\n",
    "\n",
    "# Sort columns\n",
    "rb5_df = rb5_df.sort_index(axis=1)\n",
    "\n",
    "# Reset the index\n",
    "rb5_df = rb5_df.reset_index(drop=True)\n",
    "\n",
    "# Multiply all values by 1/120 to get value in seconds\n",
    "rb5_df.iloc[:, 3:] = rb5_df.iloc[:, 3:].multiply(1/120)\n",
    "\n",
    "# Add extra columns for summary statistics\n",
    "rep_columns = [col for col in rb5_df.columns if col.startswith('Rep')]\n",
    "\n",
    "# Add summary statistic columns\n",
    "rb5_df['Min'] = rb5_df[rep_columns].min(axis=1)\n",
    "rb5_df['Mean'] = rb5_df[rep_columns].mean(axis=1)\n",
    "rb5_df['Median'] = rb5_df[rep_columns].median(axis=1)\n",
    "rb5_df['Max'] = rb5_df[rep_columns].max(axis=1)\n",
    "rb5_df['StdDev'] = rb5_df[rep_columns].std(axis=1)\n",
    "\n",
    "# Calculates standard error (assuming standard deviation is population std dev)\n",
    "rb5_df['StdError'] = rb5_df.apply(lambda row: row['StdDev'] / np.sqrt(len(rep_columns)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9ae78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataframe\n",
    "rb5_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d295f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save csv\n",
    "rb5_df.to_csv('rb5_corr_seconds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0226e367",
   "metadata": {},
   "source": [
    "### 3.2.5. Create Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba9a117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the means of each phase across performance\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(rb5_df['Cycle'].astype(str) + '-P' + rb5_df['Phase'].astype(str), rb5_df['Mean'], marker='o')\n",
    "plt.xlabel('Performance Phase')\n",
    "plt.ylabel('Mean Latency (Seconds)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Mean Latency Across Performance Phases')\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c03c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots of cycle means regardless of phase\n",
    "\n",
    "# Calculate means for each cycle\n",
    "cycle_means = rb5_df.groupby('Cycle')['Mean'].mean()\n",
    "\n",
    "# Plot the box plot\n",
    "plt.figure(figsize=(6, 3.1))\n",
    "boxprops = dict(facecolor='white', color='black')\n",
    "plt.boxplot([rb5_df[rb5_df['Cycle'] == cycle]['Mean'] for cycle in rb5_df['Cycle'].unique()],\n",
    "            labels=rb5_df['Cycle'].unique(), showfliers=True, patch_artist=True, boxprops=boxprops)\n",
    "plt.xlabel('Cycle')\n",
    "plt.ylabel('Mean Latency (Seconds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('rb_5_cycle_means_box.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf298f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots of phase means regardless of cycle\n",
    "\n",
    "# Calculate means for each phase\n",
    "phase_means = rb5_df.groupby('Phase')['Mean'].mean()\n",
    "\n",
    "# Plot the box plot\n",
    "plt.figure(figsize=(6, 3.1))\n",
    "boxprops = dict(facecolor='white', color='black')  # Set box color to white\n",
    "plt.boxplot([rb5_df[rb5_df['Phase'] == phase]['Mean'] for phase in rb5_df['Phase'].unique()],\n",
    "            labels=rb5_df['Phase'].unique(), showfliers=True, patch_artist=True, boxprops=boxprops)\n",
    "plt.xlabel('Phase')\n",
    "plt.ylabel('Mean Latency (Seconds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('rb_5_phase_means_box.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1b11fa",
   "metadata": {},
   "source": [
    "### 3.2.6. Print Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70354dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for the whole DataFrame\n",
    "whole_dataframe_summary = {\n",
    "    'Min': round(rb5_df['Mean'].min(), 3),\n",
    "    'Max': round(rb5_df['Mean'].max(), 3),\n",
    "    'Mean': round(rb5_df['Mean'].mean(), 3),\n",
    "    'Median': round(rb5_df['Mean'].median(), 3),\n",
    "    'StdDev': round(rb5_df['Mean'].std(), 3),\n",
    "    'StdError': round(rb5_df['Mean'].std() / np.sqrt(len(rb5_df)), 3),\n",
    "}\n",
    "\n",
    "print(\"Summary Statistics for the Whole DataFrame:\")\n",
    "print(whole_dataframe_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26863c8b",
   "metadata": {},
   "source": [
    "### 3.3. Ten Position Markers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6159fee",
   "metadata": {},
   "source": [
    "### 3.3.1. Load Pickle File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be357650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath to pickle file containing swing_rec objects\n",
    "path = ''\n",
    "\n",
    "# Declare dictionary for correlations\n",
    "rb_10_dict = {}\n",
    "\n",
    "\n",
    "for file in sorted(os.listdir(path)):\n",
    "    \n",
    "    if '10.pkl' in file:\n",
    "        \n",
    "        filepath = path + '/' + file\n",
    "\n",
    "        # Open pickle file\n",
    "        with open(filepath, 'rb') as file:\n",
    "            \n",
    "            dicty = pickle.load(file)\n",
    "\n",
    "            # Place swing_rec objects in dict\n",
    "            for key, item in dicty.items():\n",
    "\n",
    "                rb_10_dict[key] = item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0f4cb8",
   "metadata": {},
   "source": [
    "### 3.3.2. Calculate Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2ed441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare dictionary for correlations\n",
    "rb_10_corrs_dict = {}\n",
    "\n",
    "# Iterate through swing_rec objects\n",
    "for key, item in sorted(rb_10_dict.items()):\n",
    "    \n",
    "    # Set arrays\n",
    "    top = item.top_array\n",
    "    bottom = item.bottom_array\n",
    "    \n",
    "    # Calculate correlation\n",
    "    corr = signal.correlate(bottom, top)\n",
    "\n",
    "    # Calculate correlation lags\n",
    "    lags = signal.correlation_lags(len(bottom), len(top))\n",
    "\n",
    "    # Normalise correlation\n",
    "    corr = corr/np.max(corr)\n",
    "    \n",
    "    # Find peaks in correlation\n",
    "    cpeaks = signal.find_peaks(corr)[0]\n",
    "    \n",
    "    # Find the maximum lag - provides latency in video frames\n",
    "    latency_samps = lags[cpeaks][np.where(lags[cpeaks] > 0)[0]][0]\n",
    "    \n",
    "    # Place in dict\n",
    "    rb_10_corrs_dict[key] = latency_samps\n",
    "    \n",
    "    # Plot sinusoids with latency compensation to check\n",
    "    fig = plt.figure(figsize=(12, 6), dpi=300)\n",
    "\n",
    "    plt.plot(bottom, label='Visualisation')\n",
    "    plt.plot(np.roll(top, latency_samps), label='Laser Point')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.suptitle(key)\n",
    "    plt.title('Latency: ' + str(latency_samps) + 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73919293",
   "metadata": {},
   "source": [
    "### 3.3.3. Place in dataframe and calculate summary statistics for latency in samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edf0840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract information from keys\n",
    "keys_info = [key.split('-')[:3] for key in rb_10_corrs_dict.keys()]\n",
    "\n",
    "# Create a DataFrame\n",
    "rb10_df = pd.DataFrame(keys_info, columns=['RB', 'Cycle', 'Phase'])\n",
    "\n",
    "# Drop duplicates\n",
    "rb10_df = rb10_df.drop_duplicates()\n",
    "\n",
    "# Add columns for each last part of the key\n",
    "for key, value in rb_10_corrs_dict.items():\n",
    "    last_part = key.split('-')[-1].split('.')[0]\n",
    "    column_name = f\"Rep{last_part}\"\n",
    "    rb10_df[column_name] = rb10_df.apply(lambda row: rb_10_corrs_dict.get(f\"{row['RB']}-{row['Cycle']}-{row['Phase']}-{last_part}.mp4\"), axis=1)\n",
    "\n",
    "# Sort columns\n",
    "rb10_df = rb10_df.sort_index(axis=1)\n",
    "\n",
    "# Reset the index\n",
    "rb10_df = rb10_df.reset_index(drop=True)\n",
    "\n",
    "# Add extra columns for summary statistics\n",
    "rep_columns = [col for col in rb10_df.columns if col.startswith('Rep')]\n",
    "\n",
    "# Add summary statistic columns\n",
    "rb10_df['Min'] = rb10_df[rep_columns].min(axis=1)\n",
    "rb10_df['Mean'] = rb10_df[rep_columns].mean(axis=1)\n",
    "rb10_df['Median'] = rb10_df[rep_columns].median(axis=1)\n",
    "rb10_df['Max'] = rb10_df[rep_columns].max(axis=1)\n",
    "rb10_df['StdDev'] = rb10_df[rep_columns].std(axis=1)\n",
    "\n",
    "# Calculate standard error\n",
    "rb10_df['StdError'] = rb10_df.apply(lambda row: row['StdDev'] / np.sqrt(len(rep_columns)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230fa41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataframe\n",
    "rb10_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca398fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save csv\n",
    "rb10_df.to_csv('rb10_corr_frames.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d3a6bb",
   "metadata": {},
   "source": [
    "### 3.3.4. Place in dataframe and calculate summary statistics for latency in seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166fc76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract information from keys\n",
    "keys_info = [key.split('-')[:3] for key in rb_10_corrs_dict.keys()]\n",
    "\n",
    "# Create a DataFrame\n",
    "rb10_df = pd.DataFrame(keys_info, columns=['RB', 'Cycle', 'Phase'])\n",
    "\n",
    "# Drop duplicates\n",
    "rb10_df = rb10_df.drop_duplicates()\n",
    "\n",
    "# Add columns for each last part of the key\n",
    "for key, value in rb_10_corrs_dict.items():\n",
    "    last_part = key.split('-')[-1].split('.')[0]\n",
    "    column_name = f\"Rep{last_part}\"\n",
    "    rb10_df[column_name] = rb10_df.apply(lambda row: rb_10_corrs_dict.get(f\"{row['RB']}-{row['Cycle']}-{row['Phase']}-{last_part}.mp4\"), axis=1)\n",
    "\n",
    "# Sort columns\n",
    "rb10_df = rb10_df.sort_index(axis=1)\n",
    "\n",
    "# Reset the index\n",
    "rb10_df = rb10_df.reset_index(drop=True)\n",
    "\n",
    "# Multiply all values by 1/120 to get value in seconds\n",
    "rb10_df.iloc[:, 3:] = rb10_df.iloc[:, 3:].multiply(1/120)\n",
    "\n",
    "# Add extra columns for summary statistics\n",
    "rep_columns = [col for col in rb10_df.columns if col.startswith('Rep')]\n",
    "\n",
    "# Add summary statistic columns\n",
    "rb10_df['Min'] = rb10_df[rep_columns].min(axis=1)\n",
    "rb10_df['Mean'] = rb10_df[rep_columns].mean(axis=1)\n",
    "rb10_df['Median'] = rb10_df[rep_columns].median(axis=1)\n",
    "rb10_df['Max'] = rb10_df[rep_columns].max(axis=1)\n",
    "rb10_df['StdDev'] = rb10_df[rep_columns].std(axis=1)\n",
    "\n",
    "# Calculates standard error (assuming standard deviation is population std dev)\n",
    "rb10_df['StdError'] = rb10_df.apply(lambda row: row['StdDev'] / np.sqrt(len(rep_columns)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b150763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataframe\n",
    "rb10_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1152bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save csv\n",
    "rb10_df.to_csv('rb10_corr_seconds.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3139119e",
   "metadata": {},
   "source": [
    "### 3.3.5. Create Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba9d4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the means of each phase across performance\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(rb10_df['Cycle'].astype(str) + '-P' + rb10_df['Phase'].astype(str), rb10_df['Mean'], marker='o')\n",
    "plt.xlabel('Performance Phase')\n",
    "plt.ylabel('Mean Latency (Seconds)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Mean Latency Across Performance Phases')\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c641a8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots of cycle means regardless of phase\n",
    "\n",
    "# Calculate means for each cycle\n",
    "cycle_means = rb10_df.groupby('Cycle')['Mean'].mean()\n",
    "\n",
    "# Plot the box plot\n",
    "plt.figure(figsize=(6, 3.1))\n",
    "boxprops = dict(facecolor='white', color='black')\n",
    "plt.boxplot([rb10_df[rb10_df['Cycle'] == cycle]['Mean'] for cycle in rb10_df['Cycle'].unique()],\n",
    "            labels=rb10_df['Cycle'].unique(), showfliers=True, patch_artist=True, boxprops=boxprops)\n",
    "plt.xlabel('Cycle')\n",
    "plt.ylabel('Mean Latency (Seconds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('rb_10_cycle_means_box.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0b1e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots of phase means regardless of cycle\n",
    "\n",
    "# Calculate means for each phase\n",
    "phase_means = rb10_df.groupby('Phase')['Mean'].mean()\n",
    "\n",
    "# Plot the box plot\n",
    "plt.figure(figsize=(6, 3.1))\n",
    "boxprops = dict(facecolor='white', color='black')  # Set box color to white\n",
    "plt.boxplot([rb10_df[rb10_df['Phase'] == phase]['Mean'] for phase in rb10_df['Phase'].unique()],\n",
    "            labels=rb10_df['Phase'].unique(), showfliers=True, patch_artist=True, boxprops=boxprops)\n",
    "plt.xlabel('Phase')\n",
    "plt.ylabel('Mean Latency (Seconds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('rb_10_phase_means_box.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc26a27",
   "metadata": {},
   "source": [
    "### 3.3.6. Print Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01811e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for the whole DataFrame\n",
    "whole_dataframe_summary = {\n",
    "    'Min': round(rb10_df['Mean'].min(), 3),\n",
    "    'Max': round(rb10_df['Mean'].max(), 3),\n",
    "    'Mean': round(rb10_df['Mean'].mean(), 3),\n",
    "    'Median': round(rb10_df['Mean'].median(), 3),\n",
    "    'StdDev': round(rb10_df['Mean'].std(), 3),\n",
    "    'StdError': round(rb10_df['Mean'].std() / np.sqrt(len(rb10_df)), 3),\n",
    "}\n",
    "\n",
    "print(\"Summary Statistics for the Whole DataFrame:\")\n",
    "print(whole_dataframe_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82951c4a-8eb5-42cd-8f5e-0def6b1bbd74",
   "metadata": {},
   "source": [
    "## 4. Create summarys plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ec6bc0",
   "metadata": {},
   "source": [
    "### 4.1. Box Plot of latency mean between position markers across all cycles/phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcae049-7a5f-47a3-a4ba-c8fa32c50da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [rb1_df, rb5_df, rb10_df]\n",
    "labels = [1, 5, 10]\n",
    "\n",
    "# Plot box plots for the 'Mean' column in each dataframe\n",
    "plt.figure(figsize=(6, 3.1))\n",
    "boxprops = dict(facecolor='white', color='black')\n",
    "for j, (i, df) in zip(labels, enumerate(dfs)):\n",
    "    plt.boxplot(df['Mean'], positions=[i], labels=[f'{j}'], showfliers=True, patch_artist=True, boxprops=boxprops)\n",
    "\n",
    "plt.xlabel('Position Markers')\n",
    "plt.ylabel('Latency (Seconds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('position_markers_means_box.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d40539",
   "metadata": {},
   "source": [
    "## 4.2. Plot of latency across performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b05b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the means of each phase across performance\n",
    "plt.figure(figsize=(20, 10))\n",
    "plt.plot(rb1_df['Cycle'].astype(str) + '-P' + rb1_df['Phase'].astype(str), rb1_df['Mean'], marker='o', label='Position Marker: 1')\n",
    "plt.plot(rb5_df['Cycle'].astype(str) + '-P' + rb5_df['Phase'].astype(str), rb5_df['Mean'], marker='o', label='Position Marker: 5')\n",
    "plt.plot(rb10_df['Cycle'].astype(str) + '-P' + rb10_df['Phase'].astype(str), rb10_df['Mean'], marker='o', label='Position Marker: 10')\n",
    "plt.xlabel('Performance Phase')\n",
    "plt.ylabel('Mean Latency (Seconds)')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.title('Mean Latency Across Performance Phases')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fa00c1-69be-4c8f-9ff3-bc866b895ff9",
   "metadata": {},
   "source": [
    "## 5. Statistical Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4550484-64da-4eb4-a451-2eb921d9368f",
   "metadata": {},
   "source": [
    "### 5.1. Tests across number of position markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594847d8-3774-44dd-b838-b2b5e24f2100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format dataframes as np.arrays\n",
    "rb1_data = rb1_df[rep_columns].to_numpy()\n",
    "rb5_data = rb5_df[rep_columns].to_numpy()\n",
    "rb10_data = rb10_df[rep_columns].to_numpy()\n",
    "\n",
    "rb1_data = rb1_data.flatten()\n",
    "rb5_data = rb5_data.flatten()\n",
    "rb10_data = rb10_data.flatten()\n",
    "\n",
    "# Remove nans for safety\n",
    "rb1_data = rb1_data[~np.isnan(rb1_data)]\n",
    "rb5_data = rb5_data[~np.isnan(rb5_data)]\n",
    "rb10_data = rb10_data[~np.isnan(rb10_data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6784989",
   "metadata": {},
   "source": [
    "### 5.1.1. Levene's Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ab2de8-a615-470b-babe-4ed4a09deed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = stats.levene(rb1_data, rb5_data, rb10_data, center='mean')\n",
    "statistic_rounded = round(stat, 3)\n",
    "p_value_rounded = round(p, 3)\n",
    "\n",
    "print(\"Levene Statistic:\", statistic_rounded)\n",
    "print(\"P-value:\", p_value_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9314d3",
   "metadata": {},
   "source": [
    "### 5.1.2. ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92db0112-f512-434a-ad1c-4cd23c559bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Welch's ANOVA\n",
    "# From https://github.com/scipy/scipy/issues/11122#issuecomment-587964214\n",
    "\n",
    "def welch_anova_np(*args, var_equal=False):\n",
    "    # https://svn.r-project.org/R/trunk/src/library/stats/R/oneway.test.R\n",
    "    # translated from R Welch ANOVA (not assuming equal variance)\n",
    "\n",
    "    args = [np.asarray(arg, dtype=float) for arg in args]\n",
    "    k = len(args)\n",
    "    ni =np.array([len(arg) for arg in args])\n",
    "    mi =np.array([np.mean(arg) for arg in args])\n",
    "    vi =np.array([np.var(arg,ddof=1) for arg in args])\n",
    "    wi = ni/vi\n",
    "\n",
    "    tmp =sum((1-wi/sum(wi))**2 / (ni-1))\n",
    "    tmp /= (k**2 -1)\n",
    "\n",
    "    dfbn = k - 1\n",
    "    dfwn = 1 / (3 * tmp)\n",
    "\n",
    "    m = sum(mi*wi) / sum(wi)\n",
    "    f = sum(wi * (mi - m)**2) /((dfbn) * (1 + 2 * (dfbn - 1) * tmp))\n",
    "    prob = stats.f.sf(dfbn, dfwn, f)   # equivalent to stats.f.sf\n",
    "    return f, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205d27ff-726e-4fb2-9b6d-5bfdf573289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = welch_anova_np(rb1_data, rb5_data, rb10_data)\n",
    "\n",
    "statistic_rounded = round(stat, 3)\n",
    "p_value_rounded = round(p, 3)\n",
    "\n",
    "print(\"Statistic:\", statistic_rounded)\n",
    "print(\"P-value:\", p_value_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64e89be-52c0-4324-bcf4-8fc7596534db",
   "metadata": {},
   "source": [
    "### 5.2. Tests across cycles regardless of phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bab1bb8-4117-4bb4-931b-af1f8680a339",
   "metadata": {},
   "source": [
    "### 5.2.1. One Position Marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb723012-55b4-4f8b-baa9-5fd496d0766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare dict of lists for separating cycles\n",
    "cycle_dict = {'c1':[],\n",
    "             'c2':[],\n",
    "             'c3':[],\n",
    "             'c4':[],\n",
    "             'c5':[],\n",
    "             'c6':[],\n",
    "             'c7':[]}\n",
    "\n",
    "# Place df rows into dict lists\n",
    "for _, row in rb1_df.iterrows():\n",
    "    \n",
    "    key = row['Cycle']\n",
    "    \n",
    "    for col, value in row.items():\n",
    "        \n",
    "        if 'Rep' in col:\n",
    "            \n",
    "            cycle_dict[key].append(value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447ac0dd-1f2a-41a5-aaee-861374f6fa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format as np.arrays\n",
    "c1 = np.array(cycle_dict['c1'])\n",
    "c2 = np.array(cycle_dict['c2'])\n",
    "c3 = np.array(cycle_dict['c3'])\n",
    "c4 = np.array(cycle_dict['c4'])\n",
    "c5 = np.array(cycle_dict['c5'])\n",
    "c6 = np.array(cycle_dict['c6'])\n",
    "c7 = np.array(cycle_dict['c7'])\n",
    "\n",
    "c1 = c1.flatten()\n",
    "c2 = c2.flatten()\n",
    "c3 = c3.flatten()\n",
    "c4 = c4.flatten()\n",
    "c5 = c5.flatten()\n",
    "c6 = c6.flatten()\n",
    "c7 = c7.flatten()\n",
    "\n",
    "# Remove nans for safety\n",
    "c1 = c1[~np.isnan(c1)]\n",
    "c2 = c2[~np.isnan(c2)]\n",
    "c3 = c3[~np.isnan(c3)]\n",
    "c4 = c4[~np.isnan(c4)]\n",
    "c5 = c5[~np.isnan(c5)]\n",
    "c6 = c6[~np.isnan(c6)]\n",
    "c7 = c7[~np.isnan(c7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b5602f",
   "metadata": {},
   "source": [
    "### 5.2.1.1. Levene's Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb87ce9-d6cd-42d5-a2bf-09dcfbf6e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = stats.levene(c1, c2, c3, c4, c5, c6, c7, center='mean')\n",
    "statistic_rounded = round(stat, 3)\n",
    "p_value_rounded = round(p, 3)\n",
    "\n",
    "print(\"Levene Statistic:\", statistic_rounded)\n",
    "print(\"P-value:\", p_value_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678ab1e1",
   "metadata": {},
   "source": [
    "### 5.2.1.2. ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1638d3d3-4b00-4d25-a550-57f11284dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = welch_anova_np(c1, c2, c3, c4, c5, c6, c7)\n",
    "\n",
    "statistic_rounded = round(stat, 3)\n",
    "p_value_rounded = round(p, 3)\n",
    "\n",
    "print(\"Statistic:\", statistic_rounded)\n",
    "print(\"P-value:\", p_value_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc8d6f8-d8fc-4982-80bc-26cc03867106",
   "metadata": {},
   "source": [
    "### 5.2.2. Five Position Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eca83e-fef5-434f-8628-f80f6c26975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare dict of lists for separating cycles\n",
    "cycle_dict = {'c1':[],\n",
    "             'c2':[],\n",
    "             'c3':[],\n",
    "             'c4':[],\n",
    "             'c5':[],\n",
    "             'c6':[],\n",
    "             'c7':[]}\n",
    "\n",
    "# Place df rows into dict lists\n",
    "for _, row in rb5_df.iterrows():\n",
    "    \n",
    "    key = row['Cycle']\n",
    "    \n",
    "    for col, value in row.items():\n",
    "        \n",
    "        if 'Rep' in col:\n",
    "            \n",
    "            cycle_dict[key].append(value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0e14d6-c7b4-4f93-bce9-3c979bd53983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format as np.arrays\n",
    "c1 = np.array(cycle_dict['c1'])\n",
    "c2 = np.array(cycle_dict['c2'])\n",
    "c3 = np.array(cycle_dict['c3'])\n",
    "c4 = np.array(cycle_dict['c4'])\n",
    "c5 = np.array(cycle_dict['c5'])\n",
    "c6 = np.array(cycle_dict['c6'])\n",
    "c7 = np.array(cycle_dict['c7'])\n",
    "\n",
    "c1 = c1.flatten()\n",
    "c2 = c2.flatten()\n",
    "c3 = c3.flatten()\n",
    "c4 = c4.flatten()\n",
    "c5 = c5.flatten()\n",
    "c6 = c6.flatten()\n",
    "c7 = c7.flatten()\n",
    "\n",
    "# Remove nans for safety\n",
    "c1 = c1[~np.isnan(c1)]\n",
    "c2 = c2[~np.isnan(c2)]\n",
    "c3 = c3[~np.isnan(c3)]\n",
    "c4 = c4[~np.isnan(c4)]\n",
    "c5 = c5[~np.isnan(c5)]\n",
    "c6 = c6[~np.isnan(c6)]\n",
    "c7 = c7[~np.isnan(c7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0e4c79",
   "metadata": {},
   "source": [
    "### 5.2.2.1. Levene's Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128793ec-ab0b-4507-b3b8-7b563ae9898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = stats.levene(c1, c2, c3, c4, c5, c6, c7, center='mean')\n",
    "statistic_rounded = round(stat, 3)\n",
    "p_value_rounded = round(p, 3)\n",
    "\n",
    "print(\"Levene Statistic:\", statistic_rounded)\n",
    "print(\"P-value:\", p_value_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92509bda",
   "metadata": {},
   "source": [
    "### 5.2.2.2. ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433f0b1e-4816-4624-8a47-2a22c979a67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = welch_anova_np(c1, c2, c3, c4, c5, c6, c7)\n",
    "\n",
    "statistic_rounded = round(stat, 3)\n",
    "p_value_rounded = round(p, 3)\n",
    "\n",
    "print(\"Statistic:\", statistic_rounded)\n",
    "print(\"P-value:\", p_value_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f30fe0-edc0-440b-b66f-55cf2354ba3e",
   "metadata": {},
   "source": [
    "### 5.2.3. Ten Position Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780fbb90-772b-453f-b37d-5ef4504878d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare dict of lists for separating cycles\n",
    "cycle_dict = {'c1':[],\n",
    "             'c2':[],\n",
    "             'c3':[],\n",
    "             'c4':[],\n",
    "             'c5':[],\n",
    "             'c6':[],\n",
    "             'c7':[]}\n",
    "\n",
    "# Place df rows into dict lists\n",
    "for _, row in rb10_df.iterrows():\n",
    "    \n",
    "    key = row['Cycle']\n",
    "    \n",
    "    for col, value in row.items():\n",
    "        \n",
    "        if 'Rep' in col:\n",
    "            \n",
    "            cycle_dict[key].append(value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461a9481-0a3b-4915-8b11-78dea3985207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format as np.arrays\n",
    "c1 = np.array(cycle_dict['c1'])\n",
    "c2 = np.array(cycle_dict['c2'])\n",
    "c3 = np.array(cycle_dict['c3'])\n",
    "c4 = np.array(cycle_dict['c4'])\n",
    "c5 = np.array(cycle_dict['c5'])\n",
    "c6 = np.array(cycle_dict['c6'])\n",
    "c7 = np.array(cycle_dict['c7'])\n",
    "\n",
    "c1 = c1.flatten()\n",
    "c2 = c2.flatten()\n",
    "c3 = c3.flatten()\n",
    "c4 = c4.flatten()\n",
    "c5 = c5.flatten()\n",
    "c6 = c6.flatten()\n",
    "c7 = c7.flatten()\n",
    "\n",
    "# Remove nans for safety\n",
    "c1 = c1[~np.isnan(c1)]\n",
    "c2 = c2[~np.isnan(c2)]\n",
    "c3 = c3[~np.isnan(c3)]\n",
    "c4 = c4[~np.isnan(c4)]\n",
    "c5 = c5[~np.isnan(c5)]\n",
    "c6 = c6[~np.isnan(c6)]\n",
    "c7 = c7[~np.isnan(c7)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777a749e",
   "metadata": {},
   "source": [
    "### 5.2.3.1. Levene's Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276ec394-4504-4f38-a48f-6ef6942fb3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = stats.levene(c1, c2, c3, c4, c5, c6, c7, center='mean')\n",
    "statistic_rounded = round(stat, 3)\n",
    "p_value_rounded = round(p, 3)\n",
    "\n",
    "print(\"Levene Statistic:\", statistic_rounded)\n",
    "print(\"P-value:\", p_value_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb92f1b",
   "metadata": {},
   "source": [
    "### 5.2.3.2. ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468fff28-9313-4ee3-83c5-684ca225e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = welch_anova_np(c1, c2, c3, c4, c5, c6, c7)\n",
    "\n",
    "statistic_rounded = round(stat, 3)\n",
    "p_value_rounded = round(p, 3)\n",
    "\n",
    "print(\"Statistic:\", statistic_rounded)\n",
    "print(\"P-value:\", p_value_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc8e524-8b68-4755-a8aa-3d38796cc7fa",
   "metadata": {},
   "source": [
    "### 5.3. Tests across phases regardless of cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec8f43c-f8cb-413d-83d7-ee9356d40290",
   "metadata": {},
   "source": [
    "### 5.3.1. One Position Marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aa09c1-1177-449d-8d49-b2455b4e53fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare dict of lists for separating phases\n",
    "phase_dict = {'p1':[],\n",
    "             'p2':[],\n",
    "             'p3':[],\n",
    "             'p4':[],\n",
    "             'p5':[],\n",
    "             'p6':[],\n",
    "             'p7':[],\n",
    "             'p8':[],\n",
    "             'p9':[]}\n",
    "\n",
    "# Place df rows into dict lists\n",
    "for _, row in rb1_df.iterrows():\n",
    "    \n",
    "    key = row['Phase']\n",
    "    \n",
    "    for col, value in row.items():\n",
    "        \n",
    "        if 'Rep' in col:\n",
    "            \n",
    "            phase_dict[key].append(value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acfd451-32bb-466e-a9a4-ab5b4543e99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format as np.arrays\n",
    "p1 = np.array(phase_dict['p1'])\n",
    "p2 = np.array(phase_dict['p2'])\n",
    "p3 = np.array(phase_dict['p3'])\n",
    "p4 = np.array(phase_dict['p4'])\n",
    "p5 = np.array(phase_dict['p5'])\n",
    "p6 = np.array(phase_dict['p6'])\n",
    "p7 = np.array(phase_dict['p7'])\n",
    "p8 = np.array(phase_dict['p8'])\n",
    "p9 = np.array(phase_dict['p9'])\n",
    "\n",
    "p1 = p1.flatten()\n",
    "p2 = p2.flatten()\n",
    "p3 = p3.flatten()\n",
    "p4 = p4.flatten()\n",
    "p5 = p5.flatten()\n",
    "p6 = p6.flatten()\n",
    "p7 = p7.flatten()\n",
    "p8 = p8.flatten()\n",
    "p9 = p9.flatten()\n",
    "\n",
    "# Remove nans for safety\n",
    "p1 = p1[~np.isnan(p1)]\n",
    "p2 = p2[~np.isnan(p2)]\n",
    "p3 = p3[~np.isnan(p3)]\n",
    "p4 = p4[~np.isnan(p4)]\n",
    "p5 = p5[~np.isnan(p5)]\n",
    "p6 = p6[~np.isnan(p6)]\n",
    "p7 = p7[~np.isnan(p7)]\n",
    "p8 = p8[~np.isnan(p8)]\n",
    "p9 = p9[~np.isnan(p9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7f6073",
   "metadata": {},
   "source": [
    "### 5.3.1.1. Levene's Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ca56b8-e23a-414c-8e8f-cb93765ff64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = stats.levene(p1, p2, p3, p4, p5, p6, p7, p8, p9, center='mean')\n",
    "statistic_rounded = round(stat, 3)\n",
    "p_value_rounded = round(p, 3)\n",
    "\n",
    "print(\"Levene Statistic:\", statistic_rounded)\n",
    "print(\"P-value:\", p_value_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d323048",
   "metadata": {},
   "source": [
    "### 5.3.1.2. ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f92e23-f826-4c71-a4b9-abb1e4860fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = welch_anova_np(p1, p2, p3, p4, p5, p6, p7, p8, p9)\n",
    "\n",
    "statistic_rounded = round(stat, 3)\n",
    "p_value_rounded = round(p, 3)\n",
    "\n",
    "print(\"Statistic:\", statistic_rounded)\n",
    "print(\"P-value:\", p_value_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc38ec9-3ef7-438e-b540-48a0c2b0263e",
   "metadata": {},
   "source": [
    "### 5.3.2. Five Position Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23499839-72cd-464b-be3c-73a060998eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare dict of lists for separating phases\n",
    "phase_dict = {'p1':[],\n",
    "             'p2':[],\n",
    "             'p3':[],\n",
    "             'p4':[],\n",
    "             'p5':[],\n",
    "             'p6':[],\n",
    "             'p7':[],\n",
    "             'p8':[],\n",
    "             'p9':[]}\n",
    "\n",
    "# Place df rows into dict lists\n",
    "for _, row in rb5_df.iterrows():\n",
    "    \n",
    "    key = row['Phase']\n",
    "    \n",
    "    for col, value in row.items():\n",
    "        \n",
    "        if 'Rep' in col:\n",
    "            \n",
    "            phase_dict[key].append(value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1413cbf7-370a-40d1-a405-cb59be1c4664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format as np.arrays\n",
    "p1 = np.array(phase_dict['p1'])\n",
    "p2 = np.array(phase_dict['p2'])\n",
    "p3 = np.array(phase_dict['p3'])\n",
    "p4 = np.array(phase_dict['p4'])\n",
    "p5 = np.array(phase_dict['p5'])\n",
    "p6 = np.array(phase_dict['p6'])\n",
    "p7 = np.array(phase_dict['p7'])\n",
    "p8 = np.array(phase_dict['p8'])\n",
    "p9 = np.array(phase_dict['p9'])\n",
    "\n",
    "p1 = p1.flatten()\n",
    "p2 = p2.flatten()\n",
    "p3 = p3.flatten()\n",
    "p4 = p4.flatten()\n",
    "p5 = p5.flatten()\n",
    "p6 = p6.flatten()\n",
    "p7 = p7.flatten()\n",
    "p8 = p8.flatten()\n",
    "p9 = p9.flatten()\n",
    "\n",
    "# Remove nans for safety\n",
    "p1 = p1[~np.isnan(p1)]\n",
    "p2 = p2[~np.isnan(p2)]\n",
    "p3 = p3[~np.isnan(p3)]\n",
    "p4 = p4[~np.isnan(p4)]\n",
    "p5 = p5[~np.isnan(p5)]\n",
    "p6 = p6[~np.isnan(p6)]\n",
    "p7 = p7[~np.isnan(p7)]\n",
    "p8 = p8[~np.isnan(p8)]\n",
    "p9 = p9[~np.isnan(p9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f532160",
   "metadata": {},
   "source": [
    "### 5.3.2.1. Levene's Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d14b01-822c-4a1e-95ed-0beff3a05bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = stats.levene(p1, p2, p3, p4, p5, p6, p7, p8, p9, center='mean')\n",
    "statistic_rounded = round(stat, 3)\n",
    "p_value_rounded = round(p, 3)\n",
    "\n",
    "print(\"Levene Statistic:\", statistic_rounded)\n",
    "print(\"P-value:\", p_value_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc2d356",
   "metadata": {},
   "source": [
    "### 5.3.2.2. ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0d51c1-43fa-4538-a10a-67c5afa63cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = stats.f_oneway(p1, p2, p3, p4, p5, p6, p7, p8, p9)\n",
    "\n",
    "statistic_rounded = round(stat, 3)\n",
    "p_value_rounded = round(p, 3)\n",
    "\n",
    "print(\"Statistic:\", statistic_rounded)\n",
    "print(\"P-value:\", p_value_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13659a07-8154-48b5-8bae-dd5a07dd7233",
   "metadata": {},
   "source": [
    "### 5.3.3. Ten Position Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d205c1-9eea-434e-a6ee-6f105fefd103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare dict of lists for separating phases\n",
    "phase_dict = {'p1':[],\n",
    "             'p2':[],\n",
    "             'p3':[],\n",
    "             'p4':[],\n",
    "             'p5':[],\n",
    "             'p6':[],\n",
    "             'p7':[],\n",
    "             'p8':[],\n",
    "             'p9':[]}\n",
    "\n",
    "# Place df rows into dict lists\n",
    "for _, row in rb10_df.iterrows():\n",
    "    \n",
    "    key = row['Phase']\n",
    "    \n",
    "    for col, value in row.items():\n",
    "        \n",
    "        if 'Rep' in col:\n",
    "            \n",
    "            phase_dict[key].append(value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc6269c-345e-40f3-bc56-bea8093bcc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format as np.arrays\n",
    "p1 = np.array(phase_dict['p1'])\n",
    "p2 = np.array(phase_dict['p2'])\n",
    "p3 = np.array(phase_dict['p3'])\n",
    "p4 = np.array(phase_dict['p4'])\n",
    "p5 = np.array(phase_dict['p5'])\n",
    "p6 = np.array(phase_dict['p6'])\n",
    "p7 = np.array(phase_dict['p7'])\n",
    "p8 = np.array(phase_dict['p8'])\n",
    "p9 = np.array(phase_dict['p9'])\n",
    "\n",
    "p1 = p1.flatten()\n",
    "p2 = p2.flatten()\n",
    "p3 = p3.flatten()\n",
    "p4 = p4.flatten()\n",
    "p5 = p5.flatten()\n",
    "p6 = p6.flatten()\n",
    "p7 = p7.flatten()\n",
    "p8 = p8.flatten()\n",
    "p9 = p9.flatten()\n",
    "\n",
    "# Remove nans for safety\n",
    "p1 = p1[~np.isnan(p1)]\n",
    "p2 = p2[~np.isnan(p2)]\n",
    "p3 = p3[~np.isnan(p3)]\n",
    "p4 = p4[~np.isnan(p4)]\n",
    "p5 = p5[~np.isnan(p5)]\n",
    "p6 = p6[~np.isnan(p6)]\n",
    "p7 = p7[~np.isnan(p7)]\n",
    "p8 = p8[~np.isnan(p8)]\n",
    "p9 = p9[~np.isnan(p9)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df92b630",
   "metadata": {},
   "source": [
    "### 5.3.3.1. Levene's Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5277d3-8495-46dc-8c65-333c07f0dd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = stats.levene(p1, p2, p3, p4, p5, p6, p7, p8, p9, center='mean')\n",
    "statistic_rounded = round(stat, 3)\n",
    "p_value_rounded = round(p, 3)\n",
    "\n",
    "print(\"Levene Statistic:\", statistic_rounded)\n",
    "print(\"P-value:\", p_value_rounded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5219b337",
   "metadata": {},
   "source": [
    "### 5.3.3.2. ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8b0c98-b710-48c2-b785-cf110f56c7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, p = stats.f_oneway(p1, p2, p3, p4, p5, p6, p7, p8, p9)\n",
    "\n",
    "statistic_rounded = round(stat, 3)\n",
    "p_value_rounded = round(p, 3)\n",
    "\n",
    "print(\"Statistic:\", statistic_rounded)\n",
    "print(\"P-value:\", p_value_rounded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
